# 데이터 전처리
## 1. 데이터 전처리 : 데이터 생성, 데이터 정제
### 데이터 생성
- 요약변수
    - 수집된 정보를 분석의 목적에 맞게 종합한 변수
    - 많은 모델에 공통으로 사용될 수 있어 재활용성이 높음 \
    (단어빈도, 상품별 구매금액, 상품별 구매량, 영화매출액 등)
- 파생변수
    - 특정한 의미를 갖는 작위적 정의에 의한 변수
    - 사용자가 특정조건을 만족하거나 특정함수에 의해 값을 만들어 의미를 부여한 변수
    - 매우 주관적일 수 있으므로 논리적 타당성을 갖춰야 함\
    (구매상품 다양성 변수, 가격선호대 변수, 라이프스타일 변수, 영화 인기도 변수)

### 데이터 정제
- 결측값 : 기록누락, 미응답, 수집오류 등의 이유로 발생
    - 결측값이 포함된 자료라도 나머지 변수의 값들은 의미있는 정보이므로 정보의 손실을 최소화하도록 결측을 처리하는 것이 바람직함

- 이상값 : 다른 데이터와 동떨어진 것
    - 다른 자료값들에 비해 멀리 떨어져 있지만 의미가 있는 값일 수도 있고 단순히 입력 오류로 발생한 값일 수도 있음

- 변수구간화 : 연속형 변수를 구간을 이용하여 범주화 하는 과정
    - 이상치 문제 완화
    - 결측치 처리방법이 될 수 있음
    - 변수간 관계가 단순화되어 분석시 과적합을 방지하고 결과 해석 용이

#### 결측값 처리법
- 완전제거법
    - 결측값이 하나 이상 포함된 자료를 제거
    - 정보의 손실로 분석 결과가 왜곡될 수 있음

- 평균대체법
    - 결측값을 해당 변수의 나머지값들의 평균으로 대체
    - 추정량의 표준오차가 과소추정되는 문제가 있음

- 핫덱대체법
    - 동일한 데이터 내에서 결측값이 발생하는 관찰치와 유사한 특성을 가진 다른 관찰치의 정보를 이용하여 대체

- 그 외 : Regression imputation, KNN imputation 등

#### 이상값의 탐지
- 상자그림 : Q1 - 1.5 * IQR 과 Q3 + 1.5 * IQR의 범위를 넘어가는 자료를 이상값으로 진단
![Alt text](/reference_machinelearning/image-1.png)

- 표준화 점수(Z-score) : 표준화 점수의 절대값이 2, 3보다 큰 경우를 이상값으로 진단

#### 이상값 처리방법
- 이상값 제외 : 처리는 간단하지만 정보손실이 발생하고 추정량 왜곡이 생길 수 있음
- 이상값 대체 : 이상값을 정상값 중 최대 또는 최소 등으로 대체
- 변수변환 : 자료값 전체에 로그변환, 제곱근 변환 등을 적용


## 2. 데이터 전처리 : 데이터 변환, 데이터 결합
### 데이터 변환
- 자료 변환을 통해 자료의 해석을 쉽고 풍부하게 하기 위한 과정
- 데이터 변환 목적
    - 분포의 대칭화
    - 산포를 비슷하게 하기 위해
    - 변수 간 관계를 단순하게 하기 위해

- 제곱근 변환 : 오른쪽 꼬리가 길 때
- 제곱 변환 : 왼쪽 꼬리가 길 때
![Alt text](/reference_machinelearning/image-2.png)

- 로그 변환 : 오른쪽 꼬리가 길 때(제곱근 변환보다 극대화)
- 지수 변환 : 왼쪽 꼬리가 길 때(제곱 변환보다 극대화)
![Alt text](/reference_machinelearning/image-3.png)

- 박스콕스 변환 
    - 제곱근 유형의 변환을 일반화(왼쪽 그래프)
    - 로그 유형의 변환을 일반화(왼쪽 그래프)
    - 제곱 유형의 변환을 일반화(오른쪽 그래프)
![Alt text](/reference_machinelearning/image-4.png)

### 데이터 결합
- 이너조인 : 두 테이블에 키가 공통으로 존재하는 레코드만 결합
- 풀아우터조인 : 두 테이블 중 어느 한쪽이라도 존재하는 키에 대한 레코드를 모두 결합
- 레프트조인 : 왼쪽 테이블에 존재하는 키에 대한 레코드를 결합
- 라이트조인 : 오른쪽 테이블에 존재하는 키에 대한 레코드를 결합

# 머신러닝의 기초
## 3. 머신러닝의 기본 개념 및 방법론의 분류
- 머신러닝 
    - 컴퓨터 시스탬에 명시적으로 프로그래밍 하지 않더라도 데이터를 스스로 학습하여 문제를 해결할 수 있게 하는 기술
    - 사람이 인지하기 어려운 복잡한 규칙과 패턴을 파악하여 의미있는 결과를 얻을 수 있음

- 머신러닝 알고리즘의 발전, 컴퓨팅 성능의 발전, 대용량 데이터의 축적 및 관리기술 발전으로 머신러닝의 활용증가

### 머신러닝 방법론
- 지도학습
    - 라벨이 있는 훈련용 데이터에서 여러 특성변수를 이용하여 목표변수인 라벨을 예측하도록 모델을 학습
    - 라벨이 연속형이면 회귀알고리즘, 라벨이 범주형이면 분류알고리즘 (회귀 : 가격, 분류 : 생존여부)
    ![Alt text](/reference_machinelearning/image-5.png)

- 비지도학습(자율학습)
    - 라벨이 없는 훈련용 데이터에서 특징 변수들 간의 관계나 유사성을 기반으로 의미있는 패턴을 추출
    - 군집화, 차원축소, 추천시스템 등에 활용
    ![Alt text](/reference_machinelearning/image-6.png)
    ![Alt text](/reference_machinelearning/image-7.png)

- 강화학습
    - 행동하는 주체가 있고 행동을 했을 때의 상태와 보상을 바꿔주는 환경으로 구성
    - 주체가 매번 어떠한 행동을 하면 환경에 의해 상태와 보상이 바뀌면서 주체는 보상이 가장 커지는 방향으로 계속 학습해 나감

## 4. 머신러닝 모델의 검증 및 평가
- 지도학습 알고리즘의 분석 절차
    1. 주어진 데이터 전처리 및 탐색
    2. 적절한 모델을 선택
    3. 주어진 데이터로 모델을 훈련
    4. 훈련된 모델을 적용하여 새로운 데이터에 대한 예측을 수행

- 과대적합 문제
    - 주어진 자료는 거의 완벽한 예측이 가능하지만 미래의 새로운 자료에 대한 예측력이 떨어지는 문제
    - 복잡한 알고리즘을 사용하여 데이터를 훈련하는 경우 과대적합 문제를 항상 염두에 두어야 함
    ![Alt text](/reference_machinelearning/image-8.png)

- 모델 평가의 필요성
    - 과대적합을 막고 일반화 오차를 줄이기 위해 새로운 데이터에 얼마나 잘 일반화될지를 파악해야 함
    - 모델 적합에 사용된 자료를 평가를 위해 재활용하지 않고, 평가만을 위한 데이터를 확보할 필요가 있음

### 모델 검증 및 평가를 위한 데이터의 구분
- Hold-out 방식 : 주어진 자료를 세 그룹으로 분할한 뒤 주어진 목적에 따라 각각 모델의 훈련, 검증, 평가에 활용
    1. 훈련 데이터 : 모델의 학습을 위해 사용되는 자료
    2. 검증 데이터 : 훈련 자료로 적합되는 모델을 최적의 성능으로 튜닝하기 위해 사용되는 자료\
    훈련에 필요한 하이퍼파라미터를 조정하거나 변수선택 등에 이용
    3. 평가 데이터 : 훈련 및 검증자료로 적합된 최종 모형이 미래에 주어질 새로운 자료에 대하여 얼마나 좋은 성과를 갖는지를 평가하는데 사용되는 자료

- K-fold 교차검증 방식 : 자료의 수가 충분하지 않은 경우에는 훈련 데이터에서 너무 많은 양의 데이터를 검증 또는 평가 데이터에 뺏기지 않도록 교차검증기법을 사용
    1. 자료를 균등하게 k개의 그룹으로 분할
    2. 각 j에 대하여 j번째 그룹을 제외한 나머지 k-1개 그룹의 자료를 이용하여 모델을 적합
    3. j번째 그룹의 자료에 적합된 모델을 적용한 뒤 예측 오차를 구함
    4. j = 1, 2, ..., k에 대하여 위의 과정을 반복한 뒤 k개의 예측오차의 평균을 구함
    5. 예측오차의 평균값을 기준으로 모델의 검증 또는 평가를 수행

### 편향-분산 트레이드 오프
- 일반화 오차 = 편향^2 + 분산
- 모델의 복잡한 정도에 따라 훈련데이터와 평가데이터의 예측오차는 아래와 같은 패턴을 보임
![Alt text](/reference_machinelearning/image-9.png)

#### 과대적합을 막기 위한 방법
- 훈련 데이터를 많이 확보
- 모델의 복잡도를 낮춤
    - 특성 변수의 수를 줄이거나 차원축소
    - 파라미터에 규제를 적용

## 5. 머신러닝 모델의 평가지표
### 회귀모델의 평가지표
- RMSE\
![Alt text](/reference_machinelearning/image-10.png)\
오차 제곱의 평균의 제곱근
- R-suare\
![Alt text](/reference_machinelearning/image-11.png)
- MAE : 오차의 부호만 제거해서 이를 평균한 값\
![Alt text](/reference_machinelearning/image-12.png)
- MAPE : 실제값 대비 오차가 차지하는 비중이 평균적으로 얼마인지 확인\
![Alt text](/reference_machinelearning/image-13.png)

### 분류모델의 평가지표
- 정오분류표
![Alt text](/reference_machinelearning/image-14.png)

- 정확도, 정분류율 : 전체 관찰치 중 정분류된 관찰치의 비중\
A + D / (A + B + C + D) = (TN + TP) / (TN + FP + FN + TP)

- 정밀도 : Positive로 예측한 것 중에 실제 범주도 Positive인 데이터의 비율\
(스팸 구분)\
D / (B + D) = TP / (FP + TP)

- 재현율 : 실제 범주가 Positive인 것 중에서 Positive로 예측된 데이터의 비율 \
(암환자 평가)\
D / (C + D) = TP / (FN + TP)

- ROC 도표 : 분류의 결정임계값에 따라 달라지는 TPR과 FPR의 조합
    1. TPR(True Positive Rate) : 1인 케이스에 대해 1로 잘 예측한 비율
    2. FPR(False Positive Rate) : 0인 케이스에 대해 1로 잘못 예측한 비율
    3. 임계값이 1이면 FPR=0, TPR=0
    4. 임계값을 1에서 0으로 낮춰감에 따라 FPR과 TPR은 동시에 증가
    5. FPR이 증가하는 정도보다 TPR이 빠르게 증가하면 이상적(왼쪽 위 꼭지점에 가까울수록 좋음)
    ![Alt text](/reference_machinelearning/image-15.png)

- AUC : ROC 곡선 아래의 면적
    - 가운데 대각선의 직선은 랜덤한 수준의 이진분류에 대응되며 이 경우 AUC는 0.5
    - 1에 가까울수록 좋은 수치
    - FPR이 작을 때 얼마나 큰 TPR을 얻는지에 따라 결정

# Feature Engineering
## 6. 특성 공학 : 개요, 특성 선택 방법론